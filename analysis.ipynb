{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99813977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìŠ¹í•˜ì°¨ ì •ë³´ 45ê±´ ë¡œë“œ ì™„ë£Œ\n",
      "=== ëª¨ë“  ë…¸ì„  ëª©ë¡ ===\n",
      "- ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸\n",
      "- ì¶œê·¼2í˜¸-í•œêµ­ì „ìê¸°ìˆ ì—°êµ¬ì›\n",
      "- ì¶œê·¼3í˜¸-íŒêµê³µì˜ì£¼ì°¨ì¥\n",
      "- ì¶œê·¼4í˜¸-Meta\n",
      "- í‡´ê·¼1í˜¸(ì „ì-í•œì–‘ì •í˜•ì™¸ê³¼)\n",
      "- í‡´ê·¼2í˜¸(ì„¸íŒŒ-í•œêµ­ëŒ€ì„œë¬¸)\n",
      "- í‡´ê·¼3í˜¸(ë°”ì´ì˜¤-íš¨ì„±ì•„íŒŒíŠ¸)\n",
      "- í‡´ê·¼4í˜¸(ë°”ì´ì˜¤-ì„ ê²½ì•„íŒŒíŠ¸1ì°¨)\n",
      "\n",
      "=== ì¶œê·¼ ë…¸ì„  ì •ë³´ ===\n",
      "ë…¸ì„ : ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸, ì¶œë°œì‹œê°„: 07:00, ì°¨ëŸ‰: ê²½ê¸°12ì–´1234\n",
      "ë…¸ì„ : ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸, ì¶œë°œì‹œê°„: 07:00, ì°¨ëŸ‰: ê²½ê¸°12ì–´1234\n",
      "ë…¸ì„ : ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸, ì¶œë°œì‹œê°„: 07:00, ì°¨ëŸ‰: ê²½ê¸°12ì–´1234\n",
      "\n",
      "=== ë…¸ì„ ë³„ ìŠ¹í•˜ì°¨ í†µê³„ ===\n",
      "ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸: ìŠ¹ì°¨ 20ëª…, í•˜ì°¨ 20ëª…, ì´ 40ëª…\n",
      "ì¶œê·¼2í˜¸-í•œêµ­ì „ìê¸°ìˆ ì—°êµ¬ì›: ìŠ¹ì°¨ 20ëª…, í•˜ì°¨ 20ëª…, ì´ 40ëª…\n",
      "ì¶œê·¼3í˜¸-íŒêµê³µì˜ì£¼ì°¨ì¥: ìŠ¹ì°¨ 36ëª…, í•˜ì°¨ 36ëª…, ì´ 72ëª…\n",
      "í‡´ê·¼1í˜¸(ì „ì-í•œì–‘ì •í˜•ì™¸ê³¼): ìŠ¹ì°¨ 3ëª…, í•˜ì°¨ 3ëª…, ì´ 6ëª…\n",
      "í‡´ê·¼2í˜¸(ì„¸íŒŒ-í•œêµ­ëŒ€ì„œë¬¸): ìŠ¹ì°¨ 20ëª…, í•˜ì°¨ 20ëª…, ì´ 40ëª…\n",
      "í‡´ê·¼3í˜¸(ë°”ì´ì˜¤-íš¨ì„±ì•„íŒŒíŠ¸): ìŠ¹ì°¨ 16ëª…, í•˜ì°¨ 16ëª…, ì´ 32ëª…\n",
      "ì¶œê·¼4í˜¸-Meta: ìŠ¹ì°¨ 18ëª…, í•˜ì°¨ 0ëª…, ì´ 18ëª…\n",
      "í‡´ê·¼4í˜¸(ë°”ì´ì˜¤-ì„ ê²½ì•„íŒŒíŠ¸1ì°¨): ìŠ¹ì°¨ 21ëª…, í•˜ì°¨ 21ëª…, ì´ 42ëª…\n",
      "\n",
      "=== ìŠ¹í•˜ì°¨ ì¸ì› ìƒìœ„ ì •ë¥˜ì¥ ===\n",
      "ì—…ìŠ¤í…Œì´ì§€ ì• ì •ì°¨: 136ëª…\n",
      "ì›í‰ê³µì˜ì£¼ì°¨ì¥ ì•: 36ëª…\n",
      "ì›í‰ê³µì˜ì£¼ì°¨ì¥ ë§ì€í¸: 33ëª…\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "def load_transport_data(json_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"ìŠ¹í•˜ì°¨ ì •ë³´ JSON íŒŒì¼ì„ ë¡œë“œí•œë‹¤.\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    print(f\"âœ… ìŠ¹í•˜ì°¨ ì •ë³´ {len(data)}ê±´ ë¡œë“œ ì™„ë£Œ\")\n",
    "    return data\n",
    "\n",
    "def get_all_routes(data: List[Dict[str, Any]]) -> List[str]:\n",
    "    \"\"\"ëª¨ë“  ë…¸ì„ ëª…ì„ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    routes = list(set([item['ë…¸ì„ ëª…'] for item in data]))\n",
    "    return sorted(routes)\n",
    "\n",
    "def get_routes_by_type(data: List[Dict[str, Any]], route_type: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"êµ¬ë¶„(ì¶œê·¼/í‡´ê·¼)ì— ë”°ë¥¸ ë…¸ì„  ì •ë³´ë¥¼ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    filtered_data = [item for item in data if route_type in item['êµ¬ë¶„']]\n",
    "    return filtered_data\n",
    "\n",
    "def get_route_details(data: List[Dict[str, Any]], route_name: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"íŠ¹ì • ë…¸ì„ ì˜ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    route_data = [item for item in data if item['ë…¸ì„ ëª…'] == route_name]\n",
    "    return sorted(route_data, key=lambda x: x['ìˆœë²ˆ'])\n",
    "\n",
    "def get_station_info(data: List[Dict[str, Any]], station_name: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"íŠ¹ì • ì •ë¥˜ì¥ì˜ ìŠ¹í•˜ì°¨ ì •ë³´ë¥¼ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    station_data = [item for item in data if station_name in item['ì •ë¥˜ì¥ëª…']]\n",
    "    return station_data\n",
    "\n",
    "def get_passenger_count_by_route(data: List[Dict[str, Any]]) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"ë…¸ì„ ë³„ ìŠ¹í•˜ì°¨ ì¸ì› í†µê³„ë¥¼ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    route_stats = {}\n",
    "    \n",
    "    for item in data:\n",
    "        route_name = item['ë…¸ì„ ëª…']\n",
    "        if route_name not in route_stats:\n",
    "            route_stats[route_name] = {'ìŠ¹ì°¨': 0, 'í•˜ì°¨': 0, 'ì´ì¸ì›': 0}\n",
    "        \n",
    "        action = item['ìŠ¹/í•˜ì°¨']\n",
    "        count = item['ì¸ì›']\n",
    "        \n",
    "        route_stats[route_name][action] += count\n",
    "        route_stats[route_name]['ì´ì¸ì›'] += count\n",
    "    \n",
    "    return route_stats\n",
    "\n",
    "def get_peak_stations(data: List[Dict[str, Any]], limit: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"ìŠ¹í•˜ì°¨ ì¸ì›ì´ ë§ì€ ì •ë¥˜ì¥ ìƒìœ„ Nê°œë¥¼ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    station_counts = {}\n",
    "    \n",
    "    for item in data:\n",
    "        station = item['ì •ë¥˜ì¥ëª…']\n",
    "        if station not in station_counts:\n",
    "            station_counts[station] = 0\n",
    "        station_counts[station] += item['ì¸ì›']\n",
    "    \n",
    "    sorted_stations = sorted(station_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [{'ì •ë¥˜ì¥ëª…': station, 'ì´ì¸ì›': count} for station, count in sorted_stations[:limit]]\n",
    "\n",
    "def get_vehicle_info(data: List[Dict[str, Any]]) -> Dict[str, List[str]]:\n",
    "    \"\"\"ì°¨ëŸ‰ë³„ ë…¸ì„  ì •ë³´ë¥¼ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    vehicle_routes = {}\n",
    "    \n",
    "    for item in data:\n",
    "        vehicle = item['ì°¨ëŸ‰ë²ˆí˜¸']\n",
    "        route = item['ë…¸ì„ ëª…']\n",
    "        \n",
    "        if vehicle not in vehicle_routes:\n",
    "            vehicle_routes[vehicle] = []\n",
    "        \n",
    "        if route not in vehicle_routes[vehicle]:\n",
    "            vehicle_routes[vehicle].append(route)\n",
    "    \n",
    "    return vehicle_routes\n",
    "\n",
    "# ìŠ¹í•˜ì°¨ ì •ë³´ ë°ì´í„° ë¡œë“œ\n",
    "transport_data = load_transport_data(\"ìŠ¹í•˜ì°¨ì •ë³´.json\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "print(\"=== ëª¨ë“  ë…¸ì„  ëª©ë¡ ===\")\n",
    "all_routes = get_all_routes(transport_data)\n",
    "for route in all_routes:\n",
    "    print(f\"- {route}\")\n",
    "\n",
    "print(\"\\n=== ì¶œê·¼ ë…¸ì„  ì •ë³´ ===\")\n",
    "commute_routes = get_routes_by_type(transport_data, \"ì¶œê·¼\")\n",
    "for route in commute_routes[:3]:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥\n",
    "    print(f\"ë…¸ì„ : {route['ë…¸ì„ ëª…']}, ì¶œë°œì‹œê°„: {route['ì¶œë°œì‹œê°„']}, ì°¨ëŸ‰: {route['ì°¨ëŸ‰ë²ˆí˜¸']}\")\n",
    "\n",
    "print(\"\\n=== ë…¸ì„ ë³„ ìŠ¹í•˜ì°¨ í†µê³„ ===\")\n",
    "route_stats = get_passenger_count_by_route(transport_data)\n",
    "for route, stats in route_stats.items():\n",
    "    print(f\"{route}: ìŠ¹ì°¨ {stats['ìŠ¹ì°¨']}ëª…, í•˜ì°¨ {stats['í•˜ì°¨']}ëª…, ì´ {stats['ì´ì¸ì›']}ëª…\")\n",
    "\n",
    "print(\"\\n=== ìŠ¹í•˜ì°¨ ì¸ì› ìƒìœ„ ì •ë¥˜ì¥ ===\")\n",
    "peak_stations = get_peak_stations(transport_data, 3)\n",
    "for station in peak_stations:\n",
    "    print(f\"{station['ì •ë¥˜ì¥ëª…']}: {station['ì´ì¸ì›']}ëª…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60830256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í†µê·¼ ìˆ˜ë‹¹ ì •ë³´ 8ê±´ ë¡œë“œ ì™„ë£Œ\n",
      "=== í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„° ìš”ì•½ ===\n",
      "ì´ ë…¸ì„  ìˆ˜: 8ê°œ\n",
      "\n",
      "êµ¬ë¶„ë³„ ë…¸ì„  ìˆ˜:\n",
      "  - ì—…ìŠ¤í…Œì´ì§€ ì¶œê·¼: 4ê°œ\n",
      "  - ì—…ìŠ¤í…Œì´ì§€ í‡´ê·¼: 4ê°œ\n",
      "\n",
      "ìš´í–‰ë‹¨ê°€ í†µê³„:\n",
      "  - ìµœê³ : 88,000ì›\n",
      "  - ìµœì €: 55,000ì›\n",
      "  - í‰ê· : 73,750ì›\n",
      "\n",
      "ì§€ê¸‰ìˆ˜ë‹¹ í†µê³„:\n",
      "  - ìµœê³ : 10,000ì›\n",
      "  - ìµœì €: 10,000ì›\n",
      "  - í‰ê· : 10,000ì›\n",
      "\n",
      "=== í†µê·¼ ìˆ˜ë‹¹ ìƒì„¸ ì •ë³´ ===\n",
      "êµ¬ë¶„              ë…¸ì„ ëª…                       ì¶œë°œì‹œê°„       ìš´í–‰ê±°ë¦¬     ìš´í–‰ë‹¨ê°€       ì§€ê¸‰ìˆ˜ë‹¹       ì•¼ê°„ìˆ˜ë‹¹      \n",
      "----------------------------------------------------------------------------------------------------\n",
      "ì—…ìŠ¤í…Œì´ì§€ ì¶œê·¼        ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸                07:00:00   10KM     73,000ì› 10,000ì› 15,000ì›\n",
      "ì—…ìŠ¤í…Œì´ì§€ ì¶œê·¼        ì¶œê·¼2í˜¸-í•œêµ­ì „ìê¸°ìˆ ì—°êµ¬ì›            07:20:00   10KM     68,000ì› 10,000ì› 15,000ì›\n",
      "ì—…ìŠ¤í…Œì´ì§€ ì¶œê·¼        ì¶œê·¼3í˜¸-íŒêµê³µì˜ì£¼ì°¨ì¥              07:15:00   10KM     87,000ì› 10,000ì› 15,000ì›\n",
      "ì—…ìŠ¤í…Œì´ì§€ ì¶œê·¼        ì¶œê·¼4í˜¸-Meta                 06:55:00   10KM     63,000ì› 10,000ì› 15,000ì›\n",
      "ì—…ìŠ¤í…Œì´ì§€ í‡´ê·¼        í‡´ê·¼1í˜¸(ì „ì-í•œì–‘ì •í˜•ì™¸ê³¼)           17:15:00   10KM     87,000ì› 10,000ì› 15,000ì›\n",
      "ì—…ìŠ¤í…Œì´ì§€ í‡´ê·¼        í‡´ê·¼2í˜¸(ì„¸íŒŒ-í•œêµ­ëŒ€ì„œë¬¸)            17:15:00   10KM     69,000ì› 10,000ì› 15,000ì›\n",
      "ì—…ìŠ¤í…Œì´ì§€ í‡´ê·¼        í‡´ê·¼3í˜¸(ë°”ì´ì˜¤-íš¨ì„±ì•„íŒŒíŠ¸)           17:15:00   10KM     55,000ì› 10,000ì› 15,000ì›\n",
      "ì—…ìŠ¤í…Œì´ì§€ í‡´ê·¼        í‡´ê·¼4í˜¸(ë°”ì´ì˜¤-ì„ ê²½ì•„íŒŒíŠ¸1ì°¨)         17:15:00   10KM     88,000ì› 10,000ì› 15,000ì›\n",
      "\n",
      "=== í†µê·¼ ìˆ˜ë‹¹ ë¹„ìš© ë¶„ì„ ===\n",
      "ì´ìš´í–‰ë‹¨ê°€: 590,000ì›\n",
      "ì´ì§€ê¸‰ìˆ˜ë‹¹: 80,000ì›\n",
      "ì´ì•¼ê°„ìˆ˜ë‹¹: 120,000ì›\n",
      "ì´ë¹„ìš©: 790,000ì›\n",
      "\n",
      "=== ì¶œê·¼ ë…¸ì„  í†µê·¼ ìˆ˜ë‹¹ ===\n",
      "ë…¸ì„ : ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸\n",
      "  ì¶œë°œì‹œê°„: 07:00:00\n",
      "  ìš´í–‰ë‹¨ê°€: 73,000ì›\n",
      "  ì§€ê¸‰ìˆ˜ë‹¹: 10,000ì›\n",
      "  ì•¼ê°„ìˆ˜ë‹¹: 15,000ì›\n",
      "\n",
      "ë…¸ì„ : ì¶œê·¼2í˜¸-í•œêµ­ì „ìê¸°ìˆ ì—°êµ¬ì›\n",
      "  ì¶œë°œì‹œê°„: 07:20:00\n",
      "  ìš´í–‰ë‹¨ê°€: 68,000ì›\n",
      "  ì§€ê¸‰ìˆ˜ë‹¹: 10,000ì›\n",
      "  ì•¼ê°„ìˆ˜ë‹¹: 15,000ì›\n",
      "\n",
      "ë…¸ì„ : ì¶œê·¼3í˜¸-íŒêµê³µì˜ì£¼ì°¨ì¥\n",
      "  ì¶œë°œì‹œê°„: 07:15:00\n",
      "  ìš´í–‰ë‹¨ê°€: 87,000ì›\n",
      "  ì§€ê¸‰ìˆ˜ë‹¹: 10,000ì›\n",
      "  ì•¼ê°„ìˆ˜ë‹¹: 15,000ì›\n",
      "\n",
      "ë…¸ì„ : ì¶œê·¼4í˜¸-Meta\n",
      "  ì¶œë°œì‹œê°„: 06:55:00\n",
      "  ìš´í–‰ë‹¨ê°€: 63,000ì›\n",
      "  ì§€ê¸‰ìˆ˜ë‹¹: 10,000ì›\n",
      "  ì•¼ê°„ìˆ˜ë‹¹: 15,000ì›\n",
      "\n",
      "=== í‡´ê·¼ ë…¸ì„  í†µê·¼ ìˆ˜ë‹¹ ===\n",
      "ë…¸ì„ : í‡´ê·¼1í˜¸(ì „ì-í•œì–‘ì •í˜•ì™¸ê³¼)\n",
      "  ì¶œë°œì‹œê°„: 17:15:00\n",
      "  ìš´í–‰ë‹¨ê°€: 87,000ì›\n",
      "  ì§€ê¸‰ìˆ˜ë‹¹: 10,000ì›\n",
      "  ì•¼ê°„ìˆ˜ë‹¹: 15,000ì›\n",
      "\n",
      "ë…¸ì„ : í‡´ê·¼2í˜¸(ì„¸íŒŒ-í•œêµ­ëŒ€ì„œë¬¸)\n",
      "  ì¶œë°œì‹œê°„: 17:15:00\n",
      "  ìš´í–‰ë‹¨ê°€: 69,000ì›\n",
      "  ì§€ê¸‰ìˆ˜ë‹¹: 10,000ì›\n",
      "  ì•¼ê°„ìˆ˜ë‹¹: 15,000ì›\n",
      "\n",
      "ë…¸ì„ : í‡´ê·¼3í˜¸(ë°”ì´ì˜¤-íš¨ì„±ì•„íŒŒíŠ¸)\n",
      "  ì¶œë°œì‹œê°„: 17:15:00\n",
      "  ìš´í–‰ë‹¨ê°€: 55,000ì›\n",
      "  ì§€ê¸‰ìˆ˜ë‹¹: 10,000ì›\n",
      "  ì•¼ê°„ìˆ˜ë‹¹: 15,000ì›\n",
      "\n",
      "ë…¸ì„ : í‡´ê·¼4í˜¸(ë°”ì´ì˜¤-ì„ ê²½ì•„íŒŒíŠ¸1ì°¨)\n",
      "  ì¶œë°œì‹œê°„: 17:15:00\n",
      "  ìš´í–‰ë‹¨ê°€: 88,000ì›\n",
      "  ì§€ê¸‰ìˆ˜ë‹¹: 10,000ì›\n",
      "  ì•¼ê°„ìˆ˜ë‹¹: 15,000ì›\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def load_commute_allowance_data(json_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"í†µê·¼ ìˆ˜ë‹¹ JSON íŒŒì¼ì„ ë¡œë“œí•œë‹¤.\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    print(f\"âœ… í†µê·¼ ìˆ˜ë‹¹ ì •ë³´ {len(data)}ê±´ ë¡œë“œ ì™„ë£Œ\")\n",
    "    return data\n",
    "\n",
    "def display_commute_allowance_summary(data: List[Dict[str, Any]]):\n",
    "    \"\"\"í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ ì¶œë ¥í•œë‹¤.\"\"\"\n",
    "    print(\"=== í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„° ìš”ì•½ ===\")\n",
    "    print(f\"ì´ ë…¸ì„  ìˆ˜: {len(data)}ê°œ\")\n",
    "    \n",
    "    # êµ¬ë¶„ë³„ í†µê³„\n",
    "    commute_types = {}\n",
    "    for item in data:\n",
    "        commute_type = item['êµ¬ë¶„']\n",
    "        if commute_type not in commute_types:\n",
    "            commute_types[commute_type] = 0\n",
    "        commute_types[commute_type] += 1\n",
    "    \n",
    "    print(\"\\nêµ¬ë¶„ë³„ ë…¸ì„  ìˆ˜:\")\n",
    "    for commute_type, count in commute_types.items():\n",
    "        print(f\"  - {commute_type}: {count}ê°œ\")\n",
    "    \n",
    "    # ìš´í–‰ë‹¨ê°€ í†µê³„\n",
    "    unit_prices = [item['ìš´í–‰ë‹¨ê°€'] for item in data]\n",
    "    print(f\"\\nìš´í–‰ë‹¨ê°€ í†µê³„:\")\n",
    "    print(f\"  - ìµœê³ : {max(unit_prices):,}ì›\")\n",
    "    print(f\"  - ìµœì €: {min(unit_prices):,}ì›\")\n",
    "    print(f\"  - í‰ê· : {sum(unit_prices)/len(unit_prices):,.0f}ì›\")\n",
    "    \n",
    "    # ì§€ê¸‰ìˆ˜ë‹¹ í†µê³„\n",
    "    allowances = [item['ì§€ê¸‰ìˆ˜ë‹¹'] for item in data]\n",
    "    print(f\"\\nì§€ê¸‰ìˆ˜ë‹¹ í†µê³„:\")\n",
    "    print(f\"  - ìµœê³ : {max(allowances):,}ì›\")\n",
    "    print(f\"  - ìµœì €: {min(allowances):,}ì›\")\n",
    "    print(f\"  - í‰ê· : {sum(allowances)/len(allowances):,.0f}ì›\")\n",
    "\n",
    "def display_commute_allowance_table(data: List[Dict[str, Any]]):\n",
    "    \"\"\"í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„°ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ì¶œë ¥í•œë‹¤.\"\"\"\n",
    "    print(\"\\n=== í†µê·¼ ìˆ˜ë‹¹ ìƒì„¸ ì •ë³´ ===\")\n",
    "    print(f\"{'êµ¬ë¶„':<15} {'ë…¸ì„ ëª…':<25} {'ì¶œë°œì‹œê°„':<10} {'ìš´í–‰ê±°ë¦¬':<8} {'ìš´í–‰ë‹¨ê°€':<10} {'ì§€ê¸‰ìˆ˜ë‹¹':<10} {'ì•¼ê°„ìˆ˜ë‹¹':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for item in data:\n",
    "        print(f\"{item['êµ¬ë¶„']:<15} {item['ë…¸ì„ ëª…']:<25} {item['ì¶œë°œì‹œê°„']:<10} {item['ìš´í–‰ê±°ë¦¬']:<8} {item['ìš´í–‰ë‹¨ê°€']:,}ì› {item['ì§€ê¸‰ìˆ˜ë‹¹']:,}ì› {item['ì•¼ê°„ìˆ˜ë‹¹']:,}ì›\")\n",
    "\n",
    "def get_commute_allowance_by_type(data: List[Dict[str, Any]], commute_type: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"êµ¬ë¶„(ì¶œê·¼/í‡´ê·¼)ì— ë”°ë¥¸ í†µê·¼ ìˆ˜ë‹¹ ì •ë³´ë¥¼ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    filtered_data = [item for item in data if commute_type in item['êµ¬ë¶„']]\n",
    "    return filtered_data\n",
    "\n",
    "def get_route_allowance_details(data: List[Dict[str, Any]], route_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"íŠ¹ì • ë…¸ì„ ì˜ í†µê·¼ ìˆ˜ë‹¹ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•œë‹¤.\"\"\"\n",
    "    route_data = [item for item in data if item['ë…¸ì„ ëª…'] == route_name]\n",
    "    if route_data:\n",
    "        return route_data[0]\n",
    "    return None\n",
    "\n",
    "def calculate_total_allowance_cost(data: List[Dict[str, Any]]) -> Dict[str, int]:\n",
    "    \"\"\"ì „ì²´ í†µê·¼ ìˆ˜ë‹¹ ë¹„ìš©ì„ ê³„ì‚°í•œë‹¤.\"\"\"\n",
    "    total_unit_price = sum(item['ìš´í–‰ë‹¨ê°€'] for item in data)\n",
    "    total_allowance = sum(item['ì§€ê¸‰ìˆ˜ë‹¹'] for item in data)\n",
    "    total_night_allowance = sum(item['ì•¼ê°„ìˆ˜ë‹¹'] for item in data)\n",
    "    \n",
    "    return {\n",
    "        'ì´ìš´í–‰ë‹¨ê°€': total_unit_price,\n",
    "        'ì´ì§€ê¸‰ìˆ˜ë‹¹': total_allowance,\n",
    "        'ì´ì•¼ê°„ìˆ˜ë‹¹': total_night_allowance,\n",
    "        'ì´ë¹„ìš©': total_unit_price + total_allowance + total_night_allowance\n",
    "    }\n",
    "\n",
    "# í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„° ë¡œë“œ\n",
    "commute_allowance_data = load_commute_allowance_data(\"í†µê·¼ìˆ˜ë‹¹.json\")\n",
    "\n",
    "# ë°ì´í„° ìš”ì•½ ì¶œë ¥\n",
    "display_commute_allowance_summary(commute_allowance_data)\n",
    "\n",
    "# ìƒì„¸ í…Œì´ë¸” ì¶œë ¥\n",
    "display_commute_allowance_table(commute_allowance_data)\n",
    "\n",
    "# ë¹„ìš© ê³„ì‚° ë° ì¶œë ¥\n",
    "print(\"\\n=== í†µê·¼ ìˆ˜ë‹¹ ë¹„ìš© ë¶„ì„ ===\")\n",
    "cost_analysis = calculate_total_allowance_cost(commute_allowance_data)\n",
    "for key, value in cost_analysis.items():\n",
    "    print(f\"{key}: {value:,}ì›\")\n",
    "\n",
    "# êµ¬ë¶„ë³„ ë¶„ì„\n",
    "print(\"\\n=== ì¶œê·¼ ë…¸ì„  í†µê·¼ ìˆ˜ë‹¹ ===\")\n",
    "commute_routes = get_commute_allowance_by_type(commute_allowance_data, \"ì¶œê·¼\")\n",
    "for route in commute_routes:\n",
    "    print(f\"ë…¸ì„ : {route['ë…¸ì„ ëª…']}\")\n",
    "    print(f\"  ì¶œë°œì‹œê°„: {route['ì¶œë°œì‹œê°„']}\")\n",
    "    print(f\"  ìš´í–‰ë‹¨ê°€: {route['ìš´í–‰ë‹¨ê°€']:,}ì›\")\n",
    "    print(f\"  ì§€ê¸‰ìˆ˜ë‹¹: {route['ì§€ê¸‰ìˆ˜ë‹¹']:,}ì›\")\n",
    "    print(f\"  ì•¼ê°„ìˆ˜ë‹¹: {route['ì•¼ê°„ìˆ˜ë‹¹']:,}ì›\")\n",
    "    print()\n",
    "\n",
    "print(\"=== í‡´ê·¼ ë…¸ì„  í†µê·¼ ìˆ˜ë‹¹ ===\")\n",
    "return_routes = get_commute_allowance_by_type(commute_allowance_data, \"í‡´ê·¼\")\n",
    "for route in return_routes:\n",
    "    print(f\"ë…¸ì„ : {route['ë…¸ì„ ëª…']}\")\n",
    "    print(f\"  ì¶œë°œì‹œê°„: {route['ì¶œë°œì‹œê°„']}\")\n",
    "    print(f\"  ìš´í–‰ë‹¨ê°€: {route['ìš´í–‰ë‹¨ê°€']:,}ì›\")\n",
    "    print(f\"  ì§€ê¸‰ìˆ˜ë‹¹: {route['ì§€ê¸‰ìˆ˜ë‹¹']:,}ì›\")\n",
    "    print(f\"  ì•¼ê°„ìˆ˜ë‹¹: {route['ì•¼ê°„ìˆ˜ë‹¹']:,}ì›\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88b68194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ëŠ” ë²„ìŠ¤ ë…¸ì„ ë³„ ìŠ¹í•˜ì°¨ ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ë…¸ì„ ë³„ ìŠ¹ê° ìˆ˜ ë¶„ì„**  \n",
      "   - íŠ¹ì • ë…¸ì„ ì˜ ì „ì²´ ìŠ¹í•˜ì°¨ ì¸ì› í†µê³„ ì œê³µ\n",
      "   - ë…¸ì„ ë³„ ë¹„êµ ë¶„ì„ (ì´ìš©ê° ìˆ˜, í˜¼ì¡ë„ ë“±)\n",
      "\n",
      "2. **ì •ë¥˜ì¥ë³„ ì´ìš© í˜„í™© ë¶„ì„**  \n",
      "   - íŠ¹ì • ì •ë¥˜ì¥ì˜ ì‹œê°„ëŒ€ë³„ ìŠ¹í•˜ì°¨ íŒ¨í„´\n",
      "   - ì£¼ìš” í™˜ìŠ¹ ì§€ì  ë˜ëŠ” í•«ìŠ¤íŒŸ ì‹ë³„\n",
      "\n",
      "3. **ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„**  \n",
      "   - ì¶œí‡´ê·¼ ì‹œê°„/ì‹¬ì•¼ ì‹œê°„ëŒ€ ë“± ì‹œê°„ëŒ€ë³„ ìˆ˜ìš” ë³€í™”\n",
      "   - ì£¼ë§ vs í‰ì¼ ì´ìš© ì¶”ì´ ë¹„êµ\n",
      "\n",
      "4. **ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì œê³µ**  \n",
      "   - ë…¸ì„  ì¦í¸/ì¶•ì†Œ í•„ìš”ì„± ì œì•ˆ\n",
      "   - ì‹ ê·œ ì •ë¥˜ì¥ ì„¤ì¹˜ì— ëŒ€í•œ íƒ€ë‹¹ì„± ê²€í† \n",
      "   - í˜¼ì¡ ì™„í™” ë°©ì•ˆ ì œì‹œ (ì˜ˆ: ê¸‰í–‰ ë…¸ì„  ë„ì…)\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, \"2023ë…„ 3ì›” Aë…¸ì„ ì˜ ì˜¤ì „ 7~9ì‹œ ìŠ¹í•˜ì°¨ ë°ì´í„°\"ë¥¼ ìš”ì²­í•˜ì‹œë©´,  \n",
      "- í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ìŠ¹ì°¨/í•˜ì°¨ ê·¸ë˜í”„  \n",
      "- ì£¼ìš” ì •ë¥˜ì¥ Top 5  \n",
      "- í˜¼ì¡ë„ ì§€ìˆ˜ (ë¶„ë‹¹ íƒ‘ìŠ¹ ì¸ì›)  \n",
      "ë“±ì„ ìƒì„¸íˆ ë¶„ì„í•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë°ì´í„°ë¥¼ ì…ë ¥í•´ì£¼ì‹œë©´ ì¦‰ì‹œ ë¶„ì„ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤! ğŸšğŸ“Š  \n",
      "(â€» í˜„ì¬ ì‹¤ì œ ë°ì´í„°ëŠ” ì—†ìœ¼ë©°, ë¶„ì„ ë°©ë²•ë¡ ë§Œ ì„¤ëª… ê°€ëŠ¥í•©ë‹ˆë‹¤)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n",
    "    base_url=\"https://api.upstage.ai/v1\"\n",
    ")\n",
    " \n",
    "stream = client.chat.completions.create(\n",
    "    model=\"solar-pro2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"ë„ˆëŠ” ë²„ìŠ¤ ë…¸ì„ ë³„ ìŠ¹í•˜ì°¨ ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ë‹¤. ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë…¸ì„ ë³„ ìŠ¹ê° ìˆ˜, ì •ë¥˜ì¥ë³„ ì´ìš© í˜„í™©, ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë“±ì„ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•œë‹¤.\n",
    "\n",
    "            ë°ì´í„°: {data}\n",
    "\n",
    "            ì§ˆë¬¸: {question}\n",
    "\n",
    "            ë‹µë³€:\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì•ˆë…• ë„ˆëŠ” ëˆ„êµ¬ë‹ˆ\"\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    " \n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d54886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë…¸ì„ ì˜ ìˆ˜ìµìœ¨ì„ ë³¼ìˆ˜ ìˆëŠ” ë¼ì¸ ê·¸ë˜í”„ ìƒì„±í•´ì¤˜\n",
      "\n",
      "line_chart\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"chart_data\": {\n",
      "        \"labels\": [\"06:55\", \"07:00\", \"07:15\", \"07:20\", \"17:15\"],\n",
      "        \"datasets\": [{\n",
      "            \"label\": \"ì¶œê·¼ ë…¸ì„  ìˆ˜ìµìœ¨ (%)\",\n",
      "            \"data\": [15.87, 13.69, 11.49, 14.71, null],\n",
      "            \"fill\": false,\n",
      "            \"borderColor\": \"rgb(75, 192, 192)\",\n",
      "            \"tension\": 0.1\n",
      "        }, {\n",
      "            \"label\": \"í‡´ê·¼ ë…¸ì„  ìˆ˜ìµìœ¨ (%)\",\n",
      "            \"data\": [null, null, null, null, 14.29],\n",
      "            \"fill\": false,\n",
      "            \"borderColor\": \"rgb(255, 99, 132)\",\n",
      "            \"tension\": 0.1\n",
      "        }]\n",
      "    },\n",
      "    \"reason\": \"ìˆ˜ìµìœ¨ ê³„ì‚°ì‹: (ì§€ê¸‰ìˆ˜ë‹¹ / ìš´í–‰ë‹¨ê°€) * 100\\n1. ì¶œê·¼ ë…¸ì„ ë³„ ìˆ˜ìµìœ¨:\\n   - ì¶œê·¼4í˜¸: (10,000 / 63,000)*100 = 15.87%\\n   - ì¶œê·¼1í˜¸: (10,000 / 73,000)*100 = 13.69%\\n   - ì¶œê·¼3í˜¸: (10,000 / 87,000)*100 = 11.49%\\n   - ì¶œê·¼2í˜¸: (10,000 / 68,000)*100 = 14.71%\\n2. í‡´ê·¼ ë…¸ì„ ë³„ ìˆ˜ìµìœ¨:\\n   - í‡´ê·¼1í˜¸: (10,000 / 87,000)*100 = 11.49%\\n   - í‡´ê·¼2í˜¸: (10,000 / 69,000)*100 = 14.49%\\n   - í‡´ê·¼3í˜¸: (10,000 / 55,000)*100 = 18.18%\\n   - í‡´ê·¼4í˜¸: (10,000 / 88,000)*100 = 11.36%\\n   - í‡´ê·¼ í‰ê· : 14.29%\\n3. ë¼ì¸ ì°¨íŠ¸ì—ëŠ” ì¶œê·¼/í‡´ê·¼ êµ¬ë¶„ê³¼ ì¶œë°œì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ í‰ê·  ìˆ˜ìµìœ¨ì„ í‘œì‹œ\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# State ì •ì˜\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    transport_data: str\n",
    "    commute_allowance_data: str\n",
    "    analysis_result: str\n",
    "    chart_type: str\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(\n",
    "    model=\"solar-pro2\",\n",
    "    api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n",
    "    base_url=\"https://api.upstage.ai/v1\"\n",
    ")\n",
    "\n",
    "# ë…¸ë“œ í•¨ìˆ˜ë“¤\n",
    "def chart_type_selector(state: GraphState):\n",
    "    \"\"\"ì°¨íŠ¸ íƒ€ì… ì„ íƒ ë…¸ë“œ\"\"\"\n",
    "    user_question = \"\"\n",
    "    if state[\"messages\"]:\n",
    "        user_question = state[\"messages\"][-1].content\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    ë„ˆëŠ” êµí†µ ë°ì´í„°ì™€ í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ë‹¤. \n",
    "    \n",
    "    ì‚¬ìš©ì ì§ˆë¬¸: {user_question}\n",
    "    \n",
    "    ì•Œë§ì€ ì°¨íŠ¸ íƒ€ì…ì„ ì„ ì •í•´ì¤˜. ì¶”ê°€ì ì¸ ë‚´ìš© í¬í•¨í•˜ì§€ ë§ê³ , ì°¨íŠ¸ íƒ€ì…ë§Œ ì˜ì–´ë¡œ ì¶œë ¥í•´ì¤˜. \n",
    "    ì„ íƒ ê°€ëŠ¥ ì°¨íŠ¸: line_chart, bar_chart, text_summary, table\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [response],\n",
    "        \"chart_type\": response.content.strip(),\n",
    "        \"transport_data\": state.get(\"transport_data\", \"\"),\n",
    "        \"commute_allowance_data\": state.get(\"commute_allowance_data\", \"\"),\n",
    "        \"analysis_result\": \"\"\n",
    "    }\n",
    "\n",
    "def generate_analytic(state: GraphState):\n",
    "    \"\"\"ì¸ì‚¬ì´íŠ¸ ìƒì„± ë…¸ë“œ\"\"\"\n",
    "    user_question = \"\"\n",
    "    if state[\"messages\"]:\n",
    "        user_question = state[\"messages\"][-2].content  # ì‚¬ìš©ì ì§ˆë¬¸ì€ ë‘ ë²ˆì§¸ ë§ˆì§€ë§‰ ë©”ì‹œì§€\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    ë„ˆëŠ” êµí†µ ë°ì´í„°ì™€ í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼. python ì½”ë“œë¡œ ì‘ì„±í•˜ì§€ë§ê³  ì˜¤ì§ ë¶„ì„ë§Œ ì‘ì„±í•´ì¤˜\n",
    "\n",
    "    ì°¨íŠ¸ íƒ€ì… ì„ íƒ ê²°ê³¼: {state.get('chart_type', '')}  \n",
    "    line chart ì¼ê²½ìš° ë°ì´í„° í˜•ì‹:\n",
    "    \n",
    "    example:\n",
    "    labels: ['January', 'February', 'March', 'April', 'May', 'June', 'July'],\n",
    "    datasets: [{{\n",
    "        label: 'My First Dataset',\n",
    "        data: [65, 59, 80, 81, 56, 55, 40],\n",
    "        fill: false,\n",
    "        borderColor: 'rgb(75, 192, 192)',\n",
    "        tension: 0.1\n",
    "    }}]\n",
    "    \n",
    "    êµí†µ ë°ì´í„°: {state.get('transport_data', '')}\n",
    "    í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„°: {state.get('commute_allowance_data', '')}\n",
    "\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸: {user_question}\n",
    "    ì„ íƒëœ ì°¨íŠ¸ íƒ€ì…: {state.get('chart_type', '')}\n",
    "    \n",
    "    ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì¤˜.\n",
    "    ì•„ë˜ì˜ output formatì— ë§ì¶° ì„ íƒí•œ ì—£ì§€ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥í•´ì¤˜, ì´ì™¸ì— ì ˆëŒ€ ë‹¤ë¥¸ ë‚´ìš©ì€ ì¶œë ¥í•˜ì§€ ë§ì•„ì¤˜.\n",
    "\n",
    "        output format:\n",
    "        ```json\n",
    "        {{\n",
    "            \"chart_data\": {{\n",
    "                \"labels\": [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\"],\n",
    "                \"datasets\": [{{\n",
    "                    \"label\": \"My First Dataset\",\n",
    "                    \"data\": [65, 59, 80, 81, 56, 55, 40],\n",
    "                    \"fill\": false,\n",
    "                    \"borderColor\": \"rgb(75, 192, 192)\",\n",
    "                    \"tension\": 0.1\n",
    "                }}]\n",
    "            }},\n",
    "            \"reason\": \"ë¶„ì„ê²°ê³¼\"\n",
    "        }}\n",
    "        ```\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [response],\n",
    "        \"analysis_result\": response.content,\n",
    "        \"chart_type\": state.get(\"chart_type\", \"\"),\n",
    "        \"transport_data\": state.get(\"transport_data\", \"\"),\n",
    "        \"commute_allowance_data\": state.get(\"commute_allowance_data\", \"\")\n",
    "    }\n",
    "\n",
    "# ê·¸ë˜í”„ êµ¬ì„±\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"chart_type_selector\", chart_type_selector)\n",
    "workflow.add_node(\"generate_analytic\", generate_analytic)\n",
    "\n",
    "# ì—£ì§€ ì„¤ì •\n",
    "workflow.set_entry_point(\"chart_type_selector\")\n",
    "workflow.add_edge(\"chart_type_selector\", \"generate_analytic\")\n",
    "workflow.add_edge(\"generate_analytic\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "transport_analyzer = workflow.compile()\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "def run_transport_analysis(user_question: str = \"\", transport_data: str = \"\", commute_allowance_data: str = \"\"):\n",
    "    \"\"\"êµí†µ ë°ì´í„° ë¶„ì„ ì‹¤í–‰\"\"\"\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=user_question)] if user_question else [],\n",
    "        \"transport_data\": transport_data,\n",
    "        \"commute_allowance_data\": commute_allowance_data,\n",
    "        \"analysis_result\": \"\",\n",
    "        \"chart_type\": \"\"\n",
    "    }\n",
    "    \n",
    "    result = transport_analyzer.invoke(initial_state)\n",
    "    return result\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# ì‹¤ì œ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬\n",
    "transport_data_str = str(transport_data)\n",
    "commute_allowance_data_str = str(commute_allowance_data)\n",
    "\n",
    "# êµí†µ ë°ì´í„° ë¶„ì„ ì‹¤í–‰\n",
    "analysis_result = run_transport_analysis(\n",
    "    user_question=\"ë…¸ì„ ì˜ ìˆ˜ìµìœ¨ì„ ë³¼ìˆ˜ ìˆëŠ” ë¼ì¸ ê·¸ë˜í”„ ìƒì„±í•´ì¤˜\",\n",
    "    transport_data=transport_data_str,\n",
    "    commute_allowance_data=commute_allowance_data_str\n",
    ")\n",
    "\n",
    "# ë¶„ì„ ê²°ê³¼ ì¶œì¤˜\n",
    "for message in analysis_result[\"messages\"]:\n",
    "    if hasattr(message, 'content'):\n",
    "        print(f\"\\n{message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ca2ac5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë²„ìŠ¤ ë…¸ì„  ìµœëŒ€ ìˆ˜ìµìœ¨ì„ ë³¼ìˆ˜ ìˆëŠ” ë¼ì¸ ê·¸ë˜í”„ ìƒì„±í•´ì¤˜\n",
      "line_chart\n",
      "{\n",
      "    \"chart_data\": {\n",
      "        \"labels\": [\"ì¶œê·¼1í˜¸\", \"ì¶œê·¼2í˜¸\", \"ì¶œê·¼3í˜¸\", \"ì¶œê·¼4í˜¸\", \"í‡´ê·¼1í˜¸\", \"í‡´ê·¼2í˜¸\", \"í‡´ê·¼3í˜¸\", \"í‡´ê·¼4í˜¸\"],\n",
      "        \"datasets\": [{\n",
      "            \"label\": \"ìˆ˜ìµìœ¨(%)\",\n",
      "            \"data\": [14.93, 14.71, 11.49, 15.87, 11.49, 14.49, 18.18, 11.36],\n",
      "            \"fill\": false,\n",
      "            \"borderColor\": \"rgb(75, 192, 192)\",\n",
      "            \"tension\": 0.1\n",
      "        }]\n",
      "    },\n",
      "    \"reason\": \"í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„°ì—ì„œ ê° ë…¸ì„ ì˜ 'ì§€ê¸‰ìˆ˜ë‹¹'ì„ 'ìš´í–‰ë‹¨ê°€'ë¡œ ë‚˜ëˆˆ ìˆ˜ìµìœ¨ì„ ê³„ì‚°í•˜ì—¬ ë¼ì¸ìœ¼ë¡œ í‘œí˜„. ì¶œê·¼ ë…¸ì„ ì€ ì¶œë°œì‹œê°„ ìˆœìœ¼ë¡œ, í‡´ê·¼ ë…¸ì„ ì€ ë…¸ì„  ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í‘œì‹œ. ê³„ì‚°ì‹: (ì§€ê¸‰ìˆ˜ë‹¹ / ìš´í–‰ë‹¨ê°€) Ã— 100\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# State ì •ì˜\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    transport_data: str\n",
    "    commute_allowance_data: str\n",
    "    analysis_result: str\n",
    "    chart_type: str\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(\n",
    "    model=\"solar-pro2\",\n",
    "    api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n",
    "    base_url=\"https://api.upstage.ai/v1\"\n",
    ")\n",
    "\n",
    "# ë…¸ë“œ í•¨ìˆ˜ë“¤\n",
    "def chart_type_selector(state: GraphState):\n",
    "    \"\"\"ì°¨íŠ¸ íƒ€ì… ì„ íƒ ë…¸ë“œ\"\"\"\n",
    "    user_question = \"\"\n",
    "    if state[\"messages\"]:\n",
    "        user_question = state[\"messages\"][-1].content\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    ë„ˆëŠ” êµí†µ ë°ì´í„°ì™€ í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ë‹¤. \n",
    "    \n",
    "    ì‚¬ìš©ì ì§ˆë¬¸: {user_question}\n",
    "    \n",
    "    ì•Œë§ì€ ì°¨íŠ¸ íƒ€ì…ì„ ì„ ì •í•´ì¤˜. ì¶”ê°€ì ì¸ ë‚´ìš© í¬í•¨í•˜ì§€ ë§ê³ , ì°¨íŠ¸ íƒ€ì…ë§Œ ì˜ì–´ë¡œ ì¶œë ¥í•´ì¤˜. \n",
    "    ì„ íƒ ê°€ëŠ¥ ì°¨íŠ¸: line_chart, bar_chart, text_summary, table\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [response],\n",
    "        \"chart_type\": response.content.strip(),\n",
    "        \"transport_data\": state.get(\"transport_data\", \"\"),\n",
    "        \"commute_allowance_data\": state.get(\"commute_allowance_data\", \"\"),\n",
    "        \"analysis_result\": \"\"\n",
    "    }\n",
    "\n",
    "def generate_analytic(state: GraphState):\n",
    "    \"\"\"ì¸ì‚¬ì´íŠ¸ ìƒì„± ë…¸ë“œ\"\"\"\n",
    "    user_question = \"\"\n",
    "    if state[\"messages\"]:\n",
    "        user_question = state[\"messages\"][-2].content  # ì‚¬ìš©ì ì§ˆë¬¸ì€ ë‘ ë²ˆì§¸ ë§ˆì§€ë§‰ ë©”ì‹œì§€\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    ë„ˆëŠ” êµí†µ ë°ì´í„°ì™€ í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼. python ì½”ë“œë¡œ ì‘ì„±í•˜ì§€ë§ê³  ì˜¤ì§ ë¶„ì„ë§Œ ì‘ì„±í•´ì¤˜\n",
    "\n",
    "    ì°¨íŠ¸ íƒ€ì… ì„ íƒ ê²°ê³¼: {state.get('chart_type', '')}  \n",
    "    line chart ì¼ê²½ìš° ë°ì´í„° í˜•ì‹:\n",
    "    \n",
    "    êµí†µ ë°ì´í„°: {state.get('transport_data', '')}\n",
    "    í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„°: {state.get('commute_allowance_data', '')}\n",
    "\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸: {user_question}\n",
    "    ì„ íƒëœ ì°¨íŠ¸ íƒ€ì…: {state.get('chart_type', '')}\n",
    "    \n",
    "    \n",
    "    ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì¤˜.\n",
    "    ë°˜ë“œì‹œ ì•„ë˜ì˜ output formatì— ë§ì¶° JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•œë‹¤. ë‹¤ë¥¸ ì„¤ëª…, ì£¼ì„, í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤. ì˜¤ì§ JSON ë°ì´í„°ë§Œ ì¶œë ¥í•œë‹¤.\n",
    "\n",
    "    output format:\n",
    "        {{\n",
    "            \"chart_data\": {{\n",
    "                \"labels\": [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\"],\n",
    "                \"datasets\": [{{\n",
    "                    \"label\": \"My First Dataset\",\n",
    "                    \"data\": [65, 59, 80, 81, 56, 55, 40],\n",
    "                    \"fill\": false,\n",
    "                    \"borderColor\": \"rgb(75, 192, 192)\",\n",
    "                    \"tension\": 0.1\n",
    "                }}]\n",
    "            }},\n",
    "            \"reason\": \"ë¶„ì„ê²°ê³¼\"\n",
    "        }}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [response],\n",
    "        \"analysis_result\": response.content,\n",
    "        \"chart_type\": state.get(\"chart_type\", \"\"),\n",
    "        \"transport_data\": state.get(\"transport_data\", \"\"),\n",
    "        \"commute_allowance_data\": state.get(\"commute_allowance_data\", \"\")\n",
    "    }\n",
    "\n",
    "# ê·¸ë˜í”„ êµ¬ì„±\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"chart_type_selector\", chart_type_selector)\n",
    "workflow.add_node(\"generate_analytic\", generate_analytic)\n",
    "\n",
    "# ì—£ì§€ ì„¤ì •\n",
    "workflow.set_entry_point(\"chart_type_selector\")\n",
    "workflow.add_edge(\"chart_type_selector\", \"generate_analytic\")\n",
    "workflow.add_edge(\"generate_analytic\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "transport_analyzer = workflow.compile()\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "def run_transport_analysis(user_question: str = \"\", transport_data: str = \"\", commute_allowance_data: str = \"\"):\n",
    "    \"\"\"êµí†µ ë°ì´í„° ë¶„ì„ ì‹¤í–‰\"\"\"\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=user_question)] if user_question else [],\n",
    "        \"transport_data\": transport_data,\n",
    "        \"commute_allowance_data\": commute_allowance_data,\n",
    "        \"analysis_result\": \"\",\n",
    "        \"chart_type\": \"\"\n",
    "    }\n",
    "    \n",
    "    result = transport_analyzer.invoke(initial_state)\n",
    "    return result\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# ì‹¤ì œ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬\n",
    "transport_data_str = str(transport_data)\n",
    "commute_allowance_data_str = str(commute_allowance_data)\n",
    "\n",
    "# êµí†µ ë°ì´í„° ë¶„ì„ ì‹¤í–‰\n",
    "analysis_result = run_transport_analysis(\n",
    "    user_question=\"ë²„ìŠ¤ ë…¸ì„  ìµœëŒ€ ìˆ˜ìµìœ¨ì„ ë³¼ìˆ˜ ìˆëŠ” ë¼ì¸ ê·¸ë˜í”„ ìƒì„±í•´ì¤˜\",\n",
    "    transport_data=transport_data_str,\n",
    "    commute_allowance_data=commute_allowance_data_str\n",
    ")\n",
    "\n",
    "# # ë¶„ì„ ê²°ê³¼ ì¶œì¤˜\n",
    "# for message in analysis_result[\"messages\"]:\n",
    "#     if hasattr(message, 'content'):\n",
    "#         print(f\"\\n{message.content}\")\n",
    "\n",
    "\n",
    "# ë¶„ì„ ê²°ê³¼ ì¶œë ¥\n",
    "for message in analysis_result[\"messages\"]:\n",
    "    if hasattr(message, 'content'):\n",
    "        print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73162267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altair_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
